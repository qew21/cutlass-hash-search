# optimized_triton_hash_search.py

import torch
import triton
import triton.language as tl
import numpy as np
import time
import random

# -----------------------------------------------------------------------------
# 1) CPU å‚è€ƒå“ˆå¸Œå‡½æ•° (ä¸è®¾å¤‡ç«¯å®Œå…¨ä¸€è‡´çš„ 15 æ¬¡è¿­ä»£ï¼Œ32-bit wrap æ¯æ­¥)
# -----------------------------------------------------------------------------
def custom_hash_cpu(val: int) -> int:
    """CPU ç‰ˆå“ˆå¸Œå‡½æ•°ï¼Œç”¨äºè®¡ç®—ç›®æ ‡å“ˆå¸Œå€¼ï¼Œæ¯”å¯¹æ—¶éªŒè¯æ­£ç¡®æ€§ã€‚"""
    h = np.uint32(val)
    for _ in range(15):
        h = (h ^ np.uint32(61)) ^ (h >> np.uint32(16))
        h = (h + (h << np.uint32(3))) & np.uint32(0xFFFFFFFF)
        h = (h ^ (h >> np.uint32(4))) & np.uint32(0xFFFFFFFF)
        h = np.uint32(h * np.uint32(0x27d4eb2d)) & np.uint32(0xFFFFFFFF)
        h = (h ^ (h >> np.uint32(15))) & np.uint32(0xFFFFFFFF)
    return int(h)


# -----------------------------------------------------------------------------
# 2) GPU ç«¯ Inline Hash: 15 æ¬¡è¿­ä»£å®Œå…¨å±•å¼€ï¼Œé¿å… for-loop å¼€é”€
# -----------------------------------------------------------------------------
@triton.jit
def inline_hash15(x: tl.uint32) -> tl.uint32:
    # --- Iteration 1 ---
    x = (x ^ 61) ^ (x >> 16)
    x = x + (x << 3)
    x = x ^ (x >> 4)
    x = x * 0x27d4eb2d
    x = x ^ (x >> 15)
    # --- Iteration 2 ---
    x = (x ^ 61) ^ (x >> 16)
    x = x + (x << 3)
    x = x ^ (x >> 4)
    x = x * 0x27d4eb2d
    x = x ^ (x >> 15)
    # --- Iteration 3 ---
    x = (x ^ 61) ^ (x >> 16)
    x = x + (x << 3)
    x = x ^ (x >> 4)
    x = x * 0x27d4eb2d
    x = x ^ (x >> 15)
    # --- Iteration 4 ---
    x = (x ^ 61) ^ (x >> 16)
    x = x + (x << 3)
    x = x ^ (x >> 4)
    x = x * 0x27d4eb2d
    x = x ^ (x >> 15)
    # --- Iteration 5 ---
    x = (x ^ 61) ^ (x >> 16)
    x = x + (x << 3)
    x = x ^ (x >> 4)
    x = x * 0x27d4eb2d
    x = x ^ (x >> 15)
    # --- Iteration 6 ---
    x = (x ^ 61) ^ (x >> 16)
    x = x + (x << 3)
    x = x ^ (x >> 4)
    x = x * 0x27d4eb2d
    x = x ^ (x >> 15)
    # --- Iteration 7 ---
    x = (x ^ 61) ^ (x >> 16)
    x = x + (x << 3)
    x = x ^ (x >> 4)
    x = x * 0x27d4eb2d
    x = x ^ (x >> 15)
    # --- Iteration 8 ---
    x = (x ^ 61) ^ (x >> 16)
    x = x + (x << 3)
    x = x ^ (x >> 4)
    x = x * 0x27d4eb2d
    x = x ^ (x >> 15)
    # --- Iteration 9 ---
    x = (x ^ 61) ^ (x >> 16)
    x = x + (x << 3)
    x = x ^ (x >> 4)
    x = x * 0x27d4eb2d
    x = x ^ (x >> 15)
    # --- Iteration 10 ---
    x = (x ^ 61) ^ (x >> 16)
    x = x + (x << 3)
    x = x ^ (x >> 4)
    x = x * 0x27d4eb2d
    x = x ^ (x >> 15)
    # --- Iteration 11 ---
    x = (x ^ 61) ^ (x >> 16)
    x = x + (x << 3)
    x = x ^ (x >> 4)
    x = x * 0x27d4eb2d
    x = x ^ (x >> 15)
    # --- Iteration 12 ---
    x = (x ^ 61) ^ (x >> 16)
    x = x + (x << 3)
    x = x ^ (x >> 4)
    x = x * 0x27d4eb2d
    x = x ^ (x >> 15)
    # --- Iteration 13 ---
    x = (x ^ 61) ^ (x >> 16)
    x = x + (x << 3)
    x = x ^ (x >> 4)
    x = x * 0x27d4eb2d
    x = x ^ (x >> 15)
    # --- Iteration 14 ---
    x = (x ^ 61) ^ (x >> 16)
    x = x + (x << 3)
    x = x ^ (x >> 4)
    x = x * 0x27d4eb2d
    x = x ^ (x >> 15)
    # --- Iteration 15 ---
    x = (x ^ 61) ^ (x >> 16)
    x = x + (x << 3)
    x = x ^ (x >> 4)
    x = x * 0x27d4eb2d
    x = x ^ (x >> 15)

    return x


# -----------------------------------------------------------------------------
# 3) ç²¾ç®€ç‰ˆ Triton Kernelï¼šç”¨ vectorized reduction æ‰¾åˆ°â€œç¬¬ä¸€ä¸ªåŒ¹é…â€ï¼Œé¿å… Python loop
# -----------------------------------------------------------------------------
@triton.jit
def gpu_bruteforce_no_reduce(
    target_hash: tl.uint32,     # scalar, è¦åŒ¹é…çš„ç›®æ ‡å“ˆå¸Œ
    max_val: tl.uint32,         # scalar, æœç´¢ä¸Šé™
    result_ptr: tl.tensor,      # device ptr, å­˜æ”¾æ‰¾åˆ°çš„ç»“æœ idx
    found_flag_ptr: tl.tensor,  # device ptr, æ ‡å¿—ä½ï¼Œ0=æœªæ‰¾åˆ°ï¼Œ1=å·²æ‰¾åˆ°
    start_idx: tl.uint32,       # scalar, æœç´¢èµ·å§‹åç§»ï¼ˆé€šå¸¸ä¼  0ï¼‰
    BLOCK_SIZE: tl.constexpr,   # ç¼–è¯‘æœŸå¸¸é‡ï¼Œblock å¤§å°ï¼ˆå¦‚ 512ï¼‰
):
    pid = tl.program_id(0)
    base = start_idx + pid * BLOCK_SIZE
    offsets = base + tl.arange(0, BLOCK_SIZE)                     # shape = (BLOCK_SIZE,)
    in_bounds_mask = offsets <= max_val                             # å¸ƒå°”å‘é‡

    # è®¡ç®—å“ˆå¸Œ
    hash_vec = inline_hash15(tl.cast(offsets, tl.uint32))          # shape = (BLOCK_SIZE,)

    # matches[i] = True å½“ offsets[i]â‰¤max_val ä¸” hash_vec[i]==target_hash
    matches = in_bounds_mask & (hash_vec == target_hash)            # å¸ƒå°”å‘é‡

    # å¦‚æœè¿™ä¸€ block æ²¡æœ‰ä»»ä½•åŒ¹é…ï¼Œå°±ç›´æ¥ return
    cnt = tl.sum(tl.cast(matches, tl.int32), axis=0)               # æ ‡é‡
    if cnt == 0:
        return

    # è‡³æ­¤ï¼Œblock å†…è‡³å°‘æœ‰ä¸€ä¸ªåŒ¹é…ã€‚æˆ‘ä»¬è¦æ‰¾â€œç¬¬ä¸€ä¸ªâ€åŒ¹é… laneã€‚
    # å…ˆæ„é€ ä¸€ä¸ªå‘é‡ï¼šmatched_offsets[i] = offsets[i] if matches[i] else (æœ€å¤§ uint32)
    big = 0xFFFFFFFF                                 
    matched_offsets = tl.where(matches, offsets, big)              # shape = (BLOCK_SIZE,)

    # min ä¼šæ‹¿åˆ°æœ€å°é‚£ä¸ªåŒ¹é…çš„ offsets
    first_match = tl.min(matched_offsets, axis=0)                  # æ ‡é‡

    # åŸå­å†™å›ï¼šåªæœ‰ç¬¬ä¸€ä¸ªçº¿ç¨‹æˆåŠŸ
    if tl.atomic_cas(found_flag_ptr, 0, 1) == 0:
        tl.store(result_ptr, first_match)


# -----------------------------------------------------------------------------
# 4) ä¸»æœºç«¯ Launch å‡½æ•°ï¼šå›ºå®š BLOCK_SIZE=512ï¼Œä¸åš autotuneï¼›ä½¿ç”¨ CUDA Event ç²¾ç¡®è®¡æ—¶
# -----------------------------------------------------------------------------
def triton_bruteforce_no_reduce(target_hash: int, max_val: int, start_idx: int = 0):
    """
    åœ¨ GPU ä¸Šåšæš´åŠ›æœç´¢ï¼š
      - target_hash: è¦åŒ¹é…çš„å“ˆå¸Œå€¼
      - max_val: æœç´¢èŒƒå›´ [0..max_val]
      - start_idx: å¯ä»¥æŒ‡å®šä»é 0 å¼€å§‹ï¼ˆé»˜è®¤ä¸º 0ï¼‰
    è¿”å›ï¼š (found_idx, elapsed_ms)
        found_idx = åŒ¹é…åˆ°çš„æœ€å° idxï¼Œå¦‚æœæ²¡æ‰¾åˆ°è¿”å› -1
        elapsed_ms = GPU kernel æ‰§è¡Œæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    """
    # 4.1) åœ¨ GPU ä¸Šå¼€è¾Ÿè¾“å‡ºç¼“å†²
    device_res  = torch.full((1,), 0xFFFFFFFF, dtype=torch.uint32, device='cuda')
    device_flag = torch.zeros((1,),    dtype=torch.int32,  device='cuda')

    # 4.2) è®¡ç®—æœç´¢ç©ºé—´å¤§å°ã€BLOCK_SIZE å’Œæ‰€éœ€ blocks æ•°
    search_space = max_val - start_idx + 1
    BLOCK_SIZE   = 512  # ç»éªŒå€¼ï¼šå¤§å¤šæ•° GPU ä¸‹ 512-lane èƒ½å…¼é¡¾å¯„å­˜å™¨å ç”¨å’Œåå
    num_blocks   = (search_space + BLOCK_SIZE - 1) // BLOCK_SIZE

    # 4.3) è®¾å®š CUDA Event æ¥ç²¾ç¡®æµ‹æ—¶
    start_evt = torch.cuda.Event(enable_timing=True)
    end_evt   = torch.cuda.Event(enable_timing=True)

    # 4.4) Launch kernel å¹¶æµ‹æ—¶
    start_evt.record()
    gpu_bruteforce_no_reduce[(num_blocks,)](
        target_hash,
        max_val,
        device_res,
        device_flag,
        start_idx,
        BLOCK_SIZE=BLOCK_SIZE
    )
    end_evt.record()
    torch.cuda.synchronize()
    elapsed_ms = start_evt.elapsed_time(end_evt)

    # 4.5) æ‹·å›ç»“æœ
    found = int(device_res.item())
    if found == 0xFFFFFFFF:
        return -1, elapsed_ms
    return found, elapsed_ms


# -----------------------------------------------------------------------------
# 5) ä¸»ç¨‹åºï¼šç¤ºä¾‹å¦‚ä½•è°ƒç”¨ï¼Œå¹¶éªŒè¯ç»“æœ
# -----------------------------------------------------------------------------
if __name__ == "__main__":
    # --- 5.1) é…ç½®æœç´¢èŒƒå›´ï¼Œéšæ„è°ƒæ•´ä»¥ä¾¿æµ‹è¯•æ€§èƒ½ ---
    MAX_CHECK = 2000_000_000   # 1e8 èŒƒå›´ä»¥å†…æµ‹è¯•å¯åœ¨å‡ ç™¾ ms å®Œæˆï¼›å¯æ”¹æˆæ›´å¤§å€¼
    SOURCE    = 142385552
    target    = custom_hash_cpu(SOURCE)

    print(f"ç›®æ ‡å“ˆå¸Œ: 0x{target:08x}")
    print(f"è¦æŸ¥æ‰¾çš„æºå€¼: {SOURCE}")
    print(f"æœç´¢èŒƒå›´: [0 .. {MAX_CHECK}]\n")

    # --- 5.2) GPU (Triton) æš´åŠ›æœç´¢ ---
    print("â–¶ï¸  å¼€å§‹ GPUï¼ˆTritonï¼‰æš´åŠ›æœç´¢ ...")
    found, gpu_time = triton_bruteforce_no_reduce(target, MAX_CHECK, 0)
    if found != -1:
        print(f"âœ… GPU æ‰¾åˆ°æºå€¼: {found}  (å“ˆå¸Œ: 0x{custom_hash_cpu(found):08x})")
    else:
        print("âŒ GPU: èŒƒå›´å†…æœªæ‰¾åˆ°æºå€¼")
    print(f"GPU æœç´¢è€—æ—¶: {gpu_time:.3f} ms\n")

    # --- 5.3) å¯¹äºä¸­å°èŒƒå›´ï¼Œå¯é€‰æ‹©è¿è¡Œ CPU æš´åŠ›æœç´¢éªŒè¯ ---
    if MAX_CHECK <= 20_000_000:
        print("â–¶ï¸  å¼€å§‹ CPU æš´åŠ›æœç´¢ ...")
        t0 = time.time()
        cpu_found = -1
        for i in range(MAX_CHECK + 1):
            if custom_hash_cpu(i) == target:
                cpu_found = i
                break
        cpu_time = (time.time() - t0) * 1000
        if cpu_found != -1:
            print(f"âœ… CPU æ‰¾åˆ°æºå€¼: {cpu_found}")
        else:
            print("âŒ CPU: èŒƒå›´å†…æœªæ‰¾åˆ°æºå€¼")
        print(f"CPU æœç´¢è€—æ—¶: {cpu_time:.3f} ms\n")
    else:
        print("âš ï¸ è·³è¿‡ CPU æœç´¢ (èŒƒå›´è¿‡å¤§)\n")

    # --- 5.4) éªŒè¯æ­£ç¡®æ€§ ---
    if found != -1:
        assert custom_hash_cpu(found) == target, "é”™è¯¯ï¼šGPU æ‰¾åˆ°çš„å€¼å“ˆå¸Œä¸åŒ¹é…ï¼"
        if found == SOURCE:
            print("ğŸ” éªŒè¯é€šè¿‡ï¼šGPU æ‰¾åˆ°çš„æºå€¼ä¸åŸå§‹ SOURCE å®Œå…¨ä¸€è‡´ã€‚")
        else:
            print("âš ï¸ GPU æ‰¾åˆ°çš„æºå€¼ä¸åŸå§‹ä¸ä¸€è‡´ï¼Œå¯èƒ½å­˜åœ¨å“ˆå¸Œç¢°æ’ã€‚")
    print("\nDone.")
